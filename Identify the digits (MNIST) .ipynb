{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corporate-spanking",
   "metadata": {},
   "source": [
    "# Identify the digits (MNIST) - Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-argument",
   "metadata": {},
   "source": [
    "Here, we need to identify the digit in given images. We have total 70,000 grayscale images, \n",
    "out of which 49,000 are part of train images with the label of digit and rest 21,000 images\n",
    "are unlabeled (known as test images). Now, We need to identify the digit for test images.\n",
    "evaluation metric of this challenge is accuracy. \n",
    "The final accuracy obtained for the test set is <b>98.98</b> on Analytics Vidhya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-charlotte",
   "metadata": {},
   "source": [
    "<b>Importing Packages</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "purple-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-language",
   "metadata": {},
   "source": [
    "<b>Reading files</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "protective-heaven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48995</th>\n",
       "      <td>48995.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48996</th>\n",
       "      <td>48996.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48997</th>\n",
       "      <td>48997.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48998</th>\n",
       "      <td>48998.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48999</th>\n",
       "      <td>48999.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  label\n",
       "0          0.png      4\n",
       "1          1.png      9\n",
       "2          2.png      1\n",
       "3          3.png      7\n",
       "4          4.png      3\n",
       "...          ...    ...\n",
       "48995  48995.png      2\n",
       "48996  48996.png      4\n",
       "48997  48997.png      9\n",
       "48998  48998.png      3\n",
       "48999  48999.png      0\n",
       "\n",
       "[49000 rows x 2 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv('C:/Users/hp/Desktop/img/train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-fairy",
   "metadata": {},
   "source": [
    "<b>Reading images and keeping the size of grayscale images as 28*28 pixels <br>\n",
    "    Also normalizing the pixels by dividing by 255</b>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "dental-spider",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "# reading the training images\n",
    "\n",
    "train_image = [ ]\n",
    "\n",
    "for i in range(df_train.shape[0]):\n",
    "\n",
    "    img = image.load_img('Desktop/img/Images/train/'+df_train['filename'][i], target_size=(28,28,1), grayscale=True)\n",
    "\n",
    "    img = image.img_to_array(img)\n",
    "    img=img.astype('float32')\n",
    "\n",
    "    img = img/255.0\n",
    "\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "composite-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dressed-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-yemen",
   "metadata": {},
   "source": [
    "<b>Visualising the 1st Training set image</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "atlantic-rental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e15f754f10>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANdklEQVR4nO3df6zV9X3H8ddLvOACOkEGpUhb27BVsqa43GEXu0bH5ig1QZO1K0s7as3wj2o06R8zLktdtiykmzbN6syu1RaXzq5JayQNacvQljVzxKtlCFLBOmYRBnbYga3CBd77435ZrnLP51zO93t+lPfzkdycc77v8z2fd46++H7v+XzP/TgiBODcd16/GwDQG4QdSIKwA0kQdiAJwg4kcX4vB5vuGXGBZvZySCCV1/UzHY9jnqxWK+y2V0j6vKRpkr4YEetKz79AM3Wll9cZEkDB1tjcstbxabztaZLulfRBSUskrba9pNPXA9BddX5nXybp+Yh4ISKOS/qqpFXNtAWgaXXCvlDSjyc83ldtewPba22P2h4d07EawwGoo07YJ/sQ4IxrbyNiJCKGI2J4SDNqDAegjjph3ydp0YTHl0raX68dAN1SJ+xPSlps+zLb0yV9VNKGZtoC0LSOp94i4oTtWyR9W+NTbw9GxM7GOgPQqFrz7BGxUdLGhnoB0EVcLgskQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IotaSzbb3Sjoq6aSkExEx3ERTAJpXK+yVayLiJw28DoAu4jQeSKJu2EPSd2w/ZXvtZE+wvdb2qO3RMR2rORyATtU9jb8qIvbbnidpk+0fRsSWiU+IiBFJI5J0kedEzfEAdKjWkT0i9le3hyQ9ImlZE00BaF7HYbc90/aFp+9LulbSjqYaA9CsOqfx8yU9Yvv06/xTRHyrka5wVqbNnt2ytuuvFxf3/c9VI8X6vT9dVKzf/djKYv3df/9Ky9rJZ3cX90WzOg57RLwg6b0N9gKgi5h6A5Ig7EAShB1IgrADSRB2IAlH9O6itos8J6708p6Nd66YdsmcYv13v7e3Ze3W2Xsa7ubs/OD4qZa1Oz95c3HfaY8/3XQ757ytsVlH4rAnq3FkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmviDk6hp2sW/XKwf++dZxXq/59JLrpje+njy37eW/0zZwseb7iY3juxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7APglZWXF+tbLr+3R5301uuvD/W7hVQ4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEsyzD4ATf3S41v47j59oWbvh27cW913yVy/VGvvZv1hQrO9e8Q8ta9s/UF4u+po/vq1Yv/ihJ4p1vFHbI7vtB20fsr1jwrY5tjfZ3lPdtl4gHMBAmMpp/JclrXjTtjskbY6IxZI2V48BDLC2YY+ILZLefJ65StL66v56Sdc32xaApnX6Ad38iDggSdXtvFZPtL3W9qjt0TGV/+YYgO7p+qfxETESEcMRMTykGd0eDkALnYb9oO0FklTdHmquJQDd0GnYN0haU91fI+nRZtoB0C1t59ltPyzpaklzbe+T9BlJ6yR9zfZNkl6U9OFuNnmumzWj3mcZn/zs7S1rv3pfeS669Qz91Ezf/7aO9x3ytGL95d85Xqxf/FDHQ6fUNuwRsbpFaXnDvQDoIi6XBZIg7EAShB1IgrADSRB2IAm+4toDe//yt4r1Tb/2N21e4ZeK1bf+4d6WtRP3l/8T/8/Hf7NY//l1R4r1jcP1ei+54T0/KNZ3zS5/2fLkK690PPa5iCM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBPHsPzNxfri+Y1vlctCQ9svibLWs3/Mt1xX3/bfEXao1dZx69nW/tLS9l/bYTL3Zt7HMRR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ59h7wyXL9WIwV6zM81PHYpTn4QffaS7OK9VNHj/aok3MDR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ59h6YO1JeNvkj3/tYsf7cn19YrP/wmi+edU+nHTj5WrG+cvTmYv0L7324WL/qgvI1BCXzn3DH++JMbY/sth+0fcj2jgnb7rL9ku1t1c/K7rYJoK6pnMZ/WdKKSbZ/LiKWVj8bm20LQNPahj0itkg63INeAHRRnQ/obrG9vTrNb7nolu21tkdtj47pWI3hANTRadjvk/QuSUslHZB0d6snRsRIRAxHxPCQZnQ4HIC6Ogp7RByMiJMRcUrS/ZKWNdsWgKZ1FHbbCyY8vEHSjlbPBTAY2s6z235Y0tWS5treJ+kzkq62vVRSSNorqTwZi6KTzz1frC++cXqxvuK313Y89tDR48X6wiefKdZv/NKNxfrua0fOuid0R9uwR8TqSTY/0IVeAHQRl8sCSRB2IAnCDiRB2IEkCDuQBF9x/QUQY+XpsfMfe6rz1+54z3GzLi5/Rbbk1VPly6enHz3V8WvjTBzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ5tlR9L8fe1+xPrrs79q8QuvjyVibWf7zxphnbxJHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ignl2FP3sLeXjwXk1jhfXbf9EsT7nu+U/Y133u/jZcGQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSYZ0ffvOeSA8X6vmPlvyuPs9P2yG57ke3Hbe+yvdP2bdX2ObY32d5T3c7ufrsAOjWV0/gTkj4dEZdLep+kT9leIukOSZsjYrGkzdVjAAOqbdgj4kBEPF3dPyppl6SFklZJWl89bb2k67vUI4AGnNUHdLbfIekKSVslzY+IA9L4PwiS5rXYZ63tUdujY+J3MKBfphx227MkfV3S7RFxZKr7RcRIRAxHxPCQZnTSI4AGTCnstoc0HvSvRMQ3qs0HbS+o6gskHepOiwCa0HbqzbYlPSBpV0TcM6G0QdIaSeuq20e70iHOWb8/p/wV1gd0WY86yWEq8+xXSfq4pGdsb6u23anxkH/N9k2SXpT04a50CKARbcMeEd+X5Bbl5c22A6BbuFwWSIKwA0kQdiAJwg4kQdiBJPiKK4p+/tbuLZu8+adL2jzjta6NnRFHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ignl2FP3BNf/etdd+7LtLi/V36omujZ0RR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ5dhRtO3xp+Qnznur4tT+0/MlifVfHr4zJcGQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSmsj77IkkPSXqLpFOSRiLi87bvkvQnkl6unnpnRGzsVqPoj2P3LCjW71n37mJ97vlHW9Z2r357m9F/1KaOszGVi2pOSPp0RDxt+0JJT9neVNU+FxF/2732ADRlKuuzH5B0oLp/1PYuSQu73RiAZp3V7+y23yHpCklbq0232N5u+0Hbs1vss9b2qO3RMR2r1y2Ajk057LZnSfq6pNsj4oik+yS9S9JSjR/5755sv4gYiYjhiBge0oz6HQPoyJTCbntI40H/SkR8Q5Ii4mBEnIyIU5Lul7Sse20CqKtt2G1b0gOSdkXEPRO2T/yY9gZJO5pvD0BTHBHlJ9jvl/Svkp7R+NSbJN0pabXGT+FD0l5JN1cf5rV0kefElV5er2MALW2NzToShz1ZbSqfxn9f0mQ7M6cO/ALhCjogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASbb/P3uhg9suS/mvCprmSftKzBs7OoPY2qH1J9NapJnt7e0T8ymSFnob9jMHt0YgY7lsDBYPa26D2JdFbp3rVG6fxQBKEHUii32Ef6fP4JYPa26D2JdFbp3rSW19/ZwfQO/0+sgPoEcIOJNGXsNteYfs528/bvqMfPbRie6/tZ2xvsz3a514etH3I9o4J2+bY3mR7T3U76Rp7fertLtsvVe/dNtsr+9TbItuP295le6ft26rtfX3vCn315H3r+e/stqdJ2i3p9yTtk/SkpNUR8WxPG2nB9l5JwxHR9wswbH9A0quSHoqIX6+2fVbS4YhYV/1DOTsi/nRAertL0qv9Xsa7Wq1owcRlxiVdL+kT6uN7V+jrI+rB+9aPI/sySc9HxAsRcVzSVyWt6kMfAy8itkg6/KbNqyStr+6v1/j/LD3XoreBEBEHIuLp6v5RSaeXGe/re1foqyf6EfaFkn484fE+DdZ67yHpO7afsr22381MYv7pZbaq23l97ufN2i7j3UtvWmZ8YN67TpY/r6sfYZ9sKalBmv+7KiJ+Q9IHJX2qOl3F1ExpGe9emWSZ8YHQ6fLndfUj7PskLZrw+FJJ+/vQx6QiYn91e0jSIxq8pagPnl5Bt7o91Od+/t8gLeM92TLjGoD3rp/Ln/cj7E9KWmz7MtvTJX1U0oY+9HEG2zOrD05ke6akazV4S1FvkLSmur9G0qN97OUNBmUZ71bLjKvP713flz+PiJ7/SFqp8U/kfyTpz/rRQ4u+3inpP6qfnf3uTdLDGj+tG9P4GdFNki6RtFnSnup2zgD19o8aX9p7u8aDtaBPvb1f478abpe0rfpZ2e/3rtBXT943LpcFkuAKOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4v8AC7IAynhQefwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "elegant-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 1, 7, 3, 2, 6, 0, 8, 5], dtype=int64)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-nursing",
   "metadata": {},
   "source": [
    "<b>One-Hot Encoding the Training labels</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "working-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_train['label']\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "figured-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 10)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "invisible-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>69995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>69996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>69997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>69998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>69999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename\n",
       "0      49000.png\n",
       "1      49001.png\n",
       "2      49002.png\n",
       "3      49003.png\n",
       "4      49004.png\n",
       "...          ...\n",
       "20995  69995.png\n",
       "20996  69996.png\n",
       "20997  69997.png\n",
       "20998  69998.png\n",
       "20999  69999.png\n",
       "\n",
       "[21000 rows x 1 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_csv('C:/Users/hp/Desktop/img/test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "powerful-concrete",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "# reading the training images\n",
    "\n",
    "test_image = [ ]\n",
    "\n",
    "for i in range(df_test.shape[0]):\n",
    "\n",
    "    img = image.load_img('Desktop/img/Images/test/'+df_test['filename'][i], target_size=(28,28,1), grayscale=True)\n",
    "\n",
    "    img = image.img_to_array(img)\n",
    "    img=img.astype('float32')\n",
    "\n",
    "    img = img/255.0\n",
    "\n",
    "    test_image.append(img)\n",
    "X_test= np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "seasonal-closing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 28, 28, 1)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "molecular-worthy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1c08f8190>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-extension",
   "metadata": {},
   "source": [
    "<b> Using Data Augmentation Technique</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ignored-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(height_shift_range=0.02,rotation_range=7)\n",
    "\n",
    "# datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "irish-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "falling-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = datagen.flow(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "color-entity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 1)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-parks",
   "metadata": {},
   "source": [
    "<b>Importing necessary Keras Packages</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "inside-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import SGD\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-opinion",
   "metadata": {},
   "source": [
    "<b>Building Convolutional model with 2 layers of Conv2D and Maxpooling layer <br>\n",
    "    And 2 fully connected layer with 256 and 128 units respectively with Relu activation function <br>\n",
    "    Finally producing the output using the softmax activation function .</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "signal-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# compile model\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-bottom",
   "metadata": {},
   "source": [
    "<b>Fitting the model with 10 epochs with size of each epoch as 490.<br>\n",
    "Training set accuracy came out to be 99.04 after the 10th epoch</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "convenient-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "490/490 [==============================] - 15s 31ms/step - loss: 0.2841 - accuracy: 0.9104\n",
      "Epoch 2/10\n",
      "490/490 [==============================] - 14s 30ms/step - loss: 0.0942 - accuracy: 0.9705\n",
      "Epoch 3/10\n",
      "490/490 [==============================] - 16s 32ms/step - loss: 0.0670 - accuracy: 0.9781\n",
      "Epoch 4/10\n",
      "490/490 [==============================] - 15s 31ms/step - loss: 0.0603 - accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "490/490 [==============================] - 15s 30ms/step - loss: 0.0567 - accuracy: 0.9813\n",
      "Epoch 6/10\n",
      "490/490 [==============================] - 14s 29ms/step - loss: 0.0446 - accuracy: 0.9858\n",
      "Epoch 7/10\n",
      "490/490 [==============================] - 15s 31ms/step - loss: 0.0375 - accuracy: 0.9889\n",
      "Epoch 8/10\n",
      "490/490 [==============================] - 14s 28ms/step - loss: 0.0392 - accuracy: 0.9879\n",
      "Epoch 9/10\n",
      "490/490 [==============================] - 14s 28ms/step - loss: 0.0357 - accuracy: 0.9895\n",
      "Epoch 10/10\n",
      "490/490 [==============================] - 14s 28ms/step - loss: 0.0313 - accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e16d54a5e0>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(it, steps_per_epoch=490, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-street",
   "metadata": {},
   "source": [
    "<b>Predicting the output on the test data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "interior-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "trying-venice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000,)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "third-simon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>69995.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>69996.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>69997.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>69998.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>69999.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  Labels\n",
       "0      49000.png       4\n",
       "1      49001.png       0\n",
       "2      49002.png       9\n",
       "3      49003.png       7\n",
       "4      49004.png       9\n",
       "...          ...     ...\n",
       "20995  69995.png       9\n",
       "20996  69996.png       2\n",
       "20997  69997.png       6\n",
       "20998  69998.png       6\n",
       "20999  69999.png       2\n",
       "\n",
       "[21000 rows x 2 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Labels']=predictions\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "olympic-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.set_index('filename',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "passive-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.rename(columns={'Labels':'label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "revised-delivery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49000.png</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49001.png</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49002.png</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49003.png</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49004.png</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995.png</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996.png</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997.png</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998.png</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999.png</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label\n",
       "filename        \n",
       "49000.png      4\n",
       "49001.png      0\n",
       "49002.png      9\n",
       "49003.png      7\n",
       "49004.png      9\n",
       "...          ...\n",
       "69995.png      9\n",
       "69996.png      2\n",
       "69997.png      6\n",
       "69998.png      6\n",
       "69999.png      2\n",
       "\n",
       "[21000 rows x 1 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-facility",
   "metadata": {},
   "source": [
    "<b>Finally saving the output in the csv format which will be submitted on Analytics Vidhya<br>\n",
    "This model gave an accuracy 0f 98.98 on the test data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "coastal-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('digit_recognizer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
